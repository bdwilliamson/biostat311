---
title: "Graphs and Descriptive Statistcs"
author: "Kelsey Grinde and Brian Williamson"
date: "10 April 2018"
output: 
  pdf_document:
    toc: true
    toc_depth: 3
urlcolor: Lavender
header-includes:
  - \usepackage[dvipsnames]{xcolor}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

## function to color text
colFmt = function(x,color){
  outputFormat = knitr::opts_knit$get("rmarkdown.pandoc.to")
  if(outputFormat == 'latex')
    paste("\\textcolor{",color,"}{",x,"}",sep="")
  else if(outputFormat == 'html')
    paste("<font color='",color,"'>",x,"</font>",sep="")
  else
    x
}
```

# Activity: graphs and descriptive statistics in R

You'll use the FEV data in all of the activities today, so first read it in:
```{r read-data, echo = TRUE}
## you may have to change the bit that reads "fev.txt" to make sure 
## that R can tell where your file is located!
fev <- read.table(file = "fev.txt", header = TRUE) 
## this is a different function than we saw before, but it does the same thing!
## check it out, just in case
head(fev)
```

## 1. Descriptive statistics

You have already seen one method for computing simple descriptive statistics: the `summary` function. 

```{r summarize, echo = TRUE}
summary(fev)
```

In the key for the first discussion section activity, you saw that `seqnbr` and `subjid` don't have meaningful descriptive statistics, since they are subject identifiers (and hence somewhat arbitrary). You also saw that to make the output from `summary` more informative for the binary variables (`sex`, `smoke`), you can code them as 0's and 1's:

```{r create-new, echo = TRUE}
## make a variable called "female", and one called "smoker"
fev$female <- fev$sex - 1
fev$smoker <- ifelse(fev$smoke == 2, 0, 1)
## re-summarize
summary(fev)
```

However, typically you will report more than just the descriptive statistics from `summary`: for example, knowing the number of observations for each variable, and the number of missing observations, is often helpful.

The `uwIntroStats` package contains functions that compute descriptive statistics easily. Load that package now. If you haven't installed `uwIntroStats` yet, make sure to run `install.packages("uwIntroStats")` prior to running line 64.

```{r load-uwIntroStats, echo = TRUE}
library("uwIntroStats")
```

One of the easiest functions to use is `descrip`. Uncomment the line in the code chunk below that only has a single `#` preceding the code, and run it. Replace the text in italics below with your observations on what information `descrip` gives you that `summary` does not, and whether or not you think this additional information is helpful.

```{r descrip-1, echo = TRUE}
descrip(fev)
```

*Here, we are looking for you to mention the extra columns that `descrip` gives you, namely `N` (the total sample size for each variable), `Msng` (the number of missing observations in each variable), and `Std Dev` (the standard deviation of each variable). We believe that this extra information is incredibly helpful: the total sample size is important when making generalizations and interpreting the summary statistics (e.g., mean, median) that are computed; the number of missing observations tells us a bit more about the data, and whether or not we need to worry about our inferences (a bit outside the scope of this class, but important to notice nonetheless); and the standard deviation gives us a second measure of how variable (or spread out) our data are.*

One of the most powerful features of `descrip` is its ability to compute and easily display `r colFmt("stratified", "blue")` descriptive statistics---here, summary measures are computed within each level of a variable (e.g., `smoker = 0` and `smoker = 1`), and displayed. Add the argument `strata = fev$smoker` to the call to `descrip` in the next code chunk, and report the mean FEV among smokers and nonsmokers. Also, why might you want to stratify by smoking status in these data? (Hint: what is the scientific question?)

```{r descrip-2, echo = TRUE}
## descriptive statistics stratified by smoking status
## you have to add the argument strata = fev$smoker!
descrip(fev, strata = fev$smoker)
```

*The scientific question that we're interested in answering here is: is smoking status associated with lung function in kids? We are using FEV as a measure of lung function, and we have smoking status on each of the kids in the study. Stratifying our descriptive statistics by smoking status allows us to easily compare FEV levels (and other variables) between smokers and nonsmokers---this descriptive analysis is important, because it shows in a couple of numbers how the data back up any statistical inference we perform.*

## 2. Improving the boxplot

You have seen a couple of examples of boxplots already: in the lecture notes for the introduction section (on slide 17) and for chapter 0 (on slide 0.27). Here, you'll improve upon the boxplot by `r colFmt("adding data points", "blue")`. For this exercise, you'll improve the boxplot from slide 17 of the introduction notes. 

You first have to create a variable in the FEV data that denotes pre-teens (defined as less than 13 years old) and teens (defined as greater than or equal to 13 years old). The logical expression that creates this variable is given by `fev$age < 13`: if a given value in the `age` variable of the `fev` dataset is less than 13, this logical expression returns `TRUE`, and otherwise it returns `FALSE`. Fill in the next code chunk to create a variable called `teen` in the `fev` data that takes on the value `1` if the study participant is a teen, and takes on the value `0` if the study participant is a pre-teen.

```{r create-teen, echo = TRUE}
## create the teen variable here! Hint: use the ifelse() function
fev$teen <- ifelse(fev$age < 13, 0, 1)
```

Now that you have a variable that differentiates teens from pre-teens, you can re-create the boxplot from slide 17 with the following code: `boxplot(fev$fev ~ fev$teen, xlab = "Age Group", ylab = "FEV (liters per second)", names = c("Pre-teen (< 13)", "Teen (13 +)"))`. Here's what each component of that line of code means, in English:

* `boxplot`: Use the `boxplot` function
* `fev$fev ~ fev$teen`: Plot the `fev` variable from the `fev` dataset on the $y$-axis, since it is on the left-hand side of the tilde (`~`)
* `fev$fev ~ fev$teen`: Plot the `teen` variable from the `fev` dataset on the $x$-axis, since it is on the right-hand side of the tilde
* `xlab = "Age Group"`: Make a label for the $x$-axis, and have it display "Age Group"
* `ylab = "FEV (liters per second)"`: Make a label for the $y$-axis, and have it display "FEV (liters per second)"
* `names = c("Pre-teen (< 13)", "Teen (13 +)")`: label the tickmarks on the $x$-axis using "Pre-teen (< 13)" and "Teen (13 +)"

Copy the code for the boxplot into the next code chunk, and run it to create the boxplot. What is this boxplot telling us about the data? What do the solid black line, box, and "whiskers" mean?

```{r boxplot-1, echo = TRUE}
## make a boxplot of FEV versus age, categorized into pre-teen and teen
boxplot(fev$fev ~ fev$teen, 
        xlab = "Age Group", ylab = "FEV (liters per second)", 
        names = c("Pre-teen (< 13)", "Teen (13 +)"))
```

*The boxplot shows that pre-teens tend to have lower FEV than teens---we can see this by looking at the medians (the solid black line), and the interquartile range (given by the upper and lower edges of the boxes). Since both the median and the interquartile range for teens is higher than those for pre-teens, we are justified in saying that pre-teens tend to have lower FEV than teens.*

*The "whiskers" are telling us something different, and the way they are computed is dependent on the software used to create the boxplot. In R, the default is to make the whiskers 1.5 times the interquartile range, but this is somewhat arbitrary. The solid horizontal line at the end of the whiskers must be a point in the dataset, and any data outside of the whisker is plotted separately. A common misconception is that these datapoints are "outliers" (defined as points that are far away from the rest of the data, in terms of the outcome); however, since R is using an arbitrary rule to draw these whiskers, be careful with whether or not you label the points as outliers.*

What would happen if we forgot some of these options? Uncomment the code in the next code chunk and run that line. Replace the text in italics below with your observations on what changed between this plot and the previous one: specifically, which plot is more informative, and why?

```{r boxplot-2, echo = TRUE}
boxplot(fev$fev ~ fev$teen)
```

*We think that the first plot is more informative---the axis labels are more helpful for understanding which variables we're looking at. Always remember to label your axes!*

One way to improve upon this boxplot (there are many!) is to add the underlying data points. This gives an additional layer of information about the spread and center of the data for each group. 

You'll proceed in three stages to add data to the boxplot: 

1. Using the `plot` function, plot the `fev` values for pre-teens; use this to create an empty plot
2. Using the `boxplot` function (with new options!) add the boxplots to the empty plot
3. Using the `points` function, add data points for both pre-teens and teens

First, focus on plotting the `fev` values for pre-teens (change the code chunk option from `eval = FALSE` to `eval = TRUE`):

```{r boxplot-3, eval = TRUE}
## plot the fev values for pre-teens only
plot(fev$teen[fev$teen == 0], fev$fev[fev$teen == 0], xlim = c(-1, 2), 
     ylim = c(0, 6), ylab = "FEV (liters per second)", 
     xlab = "Age Group", axes = FALSE, pch = 16)
```

What do you notice about this plot? Is it informative? What does the code `fev$fev[fev$teen == 0]` do? What does the code `fev$teen[fev$teen == 0]` do? (Hint: `==` means "compare the left- and right-hand sides and check if they are equal")

*In this plot, we're focusing only on those kids who are pre-teens (age <= 13), since `fev$teen == 0` returns `TRUE` only if the kid is a pre-teen; otherwise, it returns `FALSE`. We only have a single line, at zero, because that's the only data we are using on the $x$-axis. This makes it hard to tell how much data there are, because the points are all clumped together! We add random noise to the `teen` values in the next code chunk so that we can get a better sense of how much data there are in each category.*

Correct one of the issues that you should have identified, by adding some random noise to the `fev$teen` values, so that there is some visual separation between the points (this is also called `r colFmt("jittering", "blue")`). Change the code chunk option for the next chunk to `eval = TRUE` and run it; do you think that this has improved the visual layout of the plot? Can you gain a bit more information now than you had before?

```{r boxplot-4, eval = TRUE}
## set a random number seed (so that your results are reproducible; can be any number)
set.seed(1234)
## add some random noise (from a uniform distribution) to the values
pre_teen_noisy <- fev$teen[fev$teen == 0] + runif(length(fev$teen[fev$teen == 0]), -0.05, 0.05)
## plot the fev values for pre-teens only
plot(pre_teen_noisy, fev$fev[fev$teen == 0], xlim = c(-1, 2), 
     ylim = c(0, 6), ylab = "FEV (liters per second)", 
     xlab = "Age Group", axes = FALSE, pch = 16)

```

*We think so! Now it is a bit clearer that there are a lot of data in the low- to mid-range FEV levels, for pre-teens. It was hard to tell this from the plot before, without jittering. We could increase the amount of random noise (by changing the arguments to `runif` on line 150) to further increase the separation between points.*

Now create an empty plot, using similar code to before, and add the boxplots on top (again, change to `eval = TRUE`):

```{r boxplot-5, eval = TRUE}
## create any empty plot (type = "n"), but give it x- and y-axis limits, and labels
plot(1, type = "n", xlim = c(-1, 2), ylim = c(0, 6), 
     ylab = "FEV (liters per second)", xlab = "Age Group", 
     axes = FALSE, pch = 16)
## add the boxplots (set add to TRUE, but other things to FALSE since we are adding)
boxplot(fev$fev ~ fev$teen, xlab = "", ylab = "", add = TRUE, 
        at = c(0, 1), axes = FALSE, outline = FALSE)
```

Finally, run the next code chunk (after changing `eval` to `TRUE`). Comment on this plot: what do the data tell you about the relationship between FEV and age? Would you change anything about this plot (including changing the type of plot altogether) to better tell this story?

```{r boxplot-6, eval = TRUE}
## create any empty plot (type = "n"), but give it x- and y-axis limits, and labels
plot(1, type = "n", xlim = c(-1, 2), ylim = c(0, 6), 
     ylab = "FEV (liters per second)", xlab = "Age Group", 
     axes = FALSE, pch = 16)
## add the boxplots (set add to TRUE, but other things to FALSE since we are adding)
boxplot(fev$fev ~ fev$teen, xlab = "", ylab = "", add = TRUE, 
        at = c(0, 1), axes = FALSE, outline = FALSE)
## create jittered data for pre-teens and teens
set.seed(1234)
pre_teen_noisy <- fev$teen[fev$teen == 0] + runif(length(fev$teen[fev$teen == 0]), -0.05, 0.05)
teen_noisy <- fev$teen[fev$teen == 1] + runif(length(fev$teen[fev$teen == 1]), -0.05, 0.05)
## add the data points
points(pre_teen_noisy, fev$fev[fev$teen == 0], pch = 16)
points(teen_noisy, fev$fev[fev$teen == 1], pch = 16)
## add x-axis and labels
axis(side = 1, at = c(0, 1), labels = c("Pre-teen (< 13)", "Teen (13 +)"))
## add y-axis
axis(side = 2, at = seq(0, 6, by = 1))
## add a box around everything
box()
```

*The boxplots show that FEV tends to be higher in teens than in pre-teens. We might expect to see this relationship---as you grow, your lungs get larger, and thus the volume of air that you can hold increases. Since FEV measures the volume of air that you can expel in a fixed amount of time, if you can hold more air in your lungs, you can likely expel more.*

*These boxplots are a decent way of telling this story, but we would argue that a scatterplot would display the data more effectively. There, we do not have to dichotomize age into teen and pre-teen; this allows us to show how FEV increases as age increases on a continuous scale.*

## 3. Stratified scatterplots

On slide 0.32, you saw a scatterplot of FEV versus age. Here, you'll improve upon that scatterplot, by adding color to denote smokers versus nonsmokers.

First, why might you want to show smokers and nonsmokers in two different colors? What are the pros and cons of displaying all of the information in a single graph, rather than in two graphs (one for smokers, and one for nonsmokers)? 

*Our choice depends on what we want our reader to gain from looking at the plot. If we want to convey that FEV increases with increasing age, then we can leave the plot as-is. However, if our ultimate goal is to compare the FEV of smokers and nonsmokers (which it is, in this study), then we want to create a plot that helps to understand this difference, if it exists.*

*Color is an effective way of differentiating between two groups on a plot---our eyes are easily drawn to different colors (especially if there are only a few different colors on the plot). If you want to make sure that your readers will be able to differentiate between the groups even if they print in black and white (or if they're color-blind and can't distinguish between the colors you've used), then make the points different shapes as well (as we've done below, using the argument `pch`).*

*The easiest thing that we could do is create two separate scatterplots, one for each group (smokers and nonsmokers). However, it is a bit hard for our eyes to compare information in two different plot windows, so to make it easy for your reader to compare groups, always try to include the information in a single plot. We can't think of any drawbacks to doing this, in the current example. The only time we might split up the information into multiple plots is if we think that the single plot has too much going on. Remember that at the end of the day, your plots should tell a convincing story to your reader. Think hard about what you want your reader to take away!*

To color the points for smokers and nonsmokers differently, you'll use some of the tools you learned in the previous exercise by: (1) plotting the FEV values for all ages, among nonsmokers, and coloring the points blue; and (2) adding the points corresponding to the FEV values for all ages, among smokers, and coloring the points red. The next code chunk does the first part for you---your task is to add the points corresponding to smokers.

```{r scatter-1, eval = TRUE}
## plot FEV values for all ages, among nonsmokers
plot(fev$age[fev$smoker == 0], fev$fev[fev$smoker == 0], 
     xlab = "Age (years)",ylab = "FEV (liters per second)", 
     main = "FEV versus age, stratified by smoking status", 
     pch = 16, col = "blue")
## add in code to add the points for smokers, 
## colored red (Hint: use the points() function)
# note that using "subsest" is equivalent to using the brackets as I did above
points(subset(fev$age, fev$smoker == 1), 
       subset(fev$fev, fev$smoker == 1), col = "red", pch = 18)
## add a legend
legend("topleft", legend = c("Smoker", "Nonsmoker"), col = c("red", "blue"), pch = 16)
```

(*If you've updated the code chunk above correctly, your plot should have both red* **and** *blue points. If it doesn't, double check that you've added the line of code to plot FEV vs age for smokers.*)

*We had you use the above code because we had already taught you the `points` function (and Brian often adds points to a plot in his own work). However, the following code chunk produces the same graphic, in fewer lines of code (and it is a bit more intuitive to read):*

```{r scatter-1-equiv, eval = TRUE}
## plot FEV values for all ages, among smokers (red diamonds)
## and nonsmokers (blue circles)
plot(fev$age, fev$fev, xlab = "Age (years)", 
     ylab = "FEV (liters per second)", 
     main = "FEV versus age, stratified by smoking status",
     pch = ifelse(fev$smoker == 0, 16, 18),
     col = ifelse(fev$smoker == 0, "blue", "red"))
## add a legend
legend("topleft", legend = c("Smoker", "Nonsmoker"), 
       col = c("red", "blue"), pch = c(18, 16))
```

Based on this plot, describe the trends in FEV with age for smokers and nonsmokers, separately. Additionally, describe the difference in the trends in FEV with age between smokers and nonsmokers.

*FEV tends to increase with age, for nonsmokers. When we restrict our attention to smokers, it seems that FEV either remains constant with age or perhaps decreases with age.*

*There is a striking difference in the relationship between FEV and age between smokers and nonsmokers, where in smokers, FEV appears to decrease with increasing age, while the opposite is true in nonsmokers.*

## 4. Linear regression

In Chapter 1, we looked at an example where we fit the regression model $$E[\text{FEV}|\text{age}]=\beta_0+\beta_1\text{age}.$$

Use `R` to fit that regression model now. (Hint: look at slide 1.24)

```{r lin-reg, eval = TRUE}
## ilinear regression
## outcome = fev, predictor = age
regress('mean', fev ~ age, data = fev)
```

(*This $\uparrow$ is what you should have seen. However, remember that in general it is NOT a good idea to include raw `R` output like this in a formal report.*)

Interpret the results of your linear regression analysis. (**Make sure you include and interpret all 4 important numbers!**)

*These data provide evidence to suggest that older children tend to have higher FEV. We estimate that the difference in average FEV comparing two groups of children that differ by one year in age is 0.22 liters per second, with higher average FEV in the older of the two groups. Based on a 95% confidence interval, this estimated difference would not be judged unusual if the true difference were between 0.20 and 0.24 liters per second. Furthermore, these data provide strong evidence that the difference in mean FEV between groups of children that differ by one year in age is significantly different from zero (p<0.001).*

Now, we will create a graphical representation of our linear regression results, by adding our fitted linear regression line to the scatterplot of FEV vs age. In the code chunk below, update `b0` with the estimated intercept from above, `b1` with the estimated slope, and change `eval=TRUE` to display your plot in your knitted document.

```{r lin-reg-scatter, eval = TRUE}
# plot FEV vs age
plot(fev$fev ~ fev$age, pch=16,
     xlim = c(0,20), ylim = c(0,8),
     xlab = "Age (years)",ylab = "FEV (liters per second)", 
     main = "FEV versus age")

# add line of best fit
b0 <- 0.4316 # estimated beta_0
b1 <- 0.2220 # esimtated beta_1
abline(a = b0, b = b1, col='red') # add line with intercept = b0, slope = b1

# add a legend
legend('topleft', 
       legend=c('Data','Linear Regression Line'),
       col = c('black','red'), lty = c(NA,1),
       pch = c(16,NA))
```

Looking at the plot you've created, does your linear regression line seem like it provides a good fit to our observed data? (*Hint: if it doesn't, you probably forgot to update `b0` and `b1` in the code chunk above.*)

*Yes, this does look like a good fit! In fact, it is actually the line that provides the "best" fit to these data (where best is defined on the basis of the sum of squared distances from the points to the line). In this example, it also looks like a line does a pretty good job of describing the relationship between FEV and age (in other cases, even the "best" line might not look like a good fit if the relationship between $Y$ and $X$ is not linear).*

Our estimated linear regression line is one type of `r colFmt("trend line", "blue")` that shows the relationship between FEV and age (in this case, it's the `r colFmt("line of best fit", "blue")`, or the line with the smallest sum of squared residuals). Another type of trend line is a `r colFmt("loess smooth", "blue")`. 

Best fitting lines (linear regression lines) minimize the squared difference between each data point and the line: the idea is that the best fitting line should not be too far away from any of the data points. If you draw a vertical line from each data point to the line, and square it (this makes sure that being above and below the line don't cancel each other out), you have a measure of the distance between the line and each data point. Making this difference small means that the line describes the data fairly well.

Loess smooths break up the $x$-axis of the data into small chunks, and fit a best fitting line within each chunk. The best fitting lines are then connected together. These smooths are thus a bit more flexible than just fitting a straight line to the data---they can help determine if there are more complex (e.g., nonlinear) patterns going on.

Now, let's create the same scatterplot as above, but also add a loess smooth. Run the code chunk below, but update `b0` and `b1` and change `eval=FALSE` to `eval=TRUE`.

```{r lin-reg-scatter-2, eval = TRUE}
# plot FEV vs age
plot(fev$fev ~ fev$age, pch=16,
     xlim = c(0,20), ylim = c(0,8),
     xlab = "Age (years)",ylab = "FEV (liters per second)", 
     main = "FEV versus age")

# add line of best fit
b0 <- 0.4316 # estimated beta_0
b1 <- 0.2220 # esimtated beta_1
abline(a = b0, b = b1, col='red') # add line with intercept = b0, slope = b1

# add a loess smooth
loess <- lowess(x = fev$age, y = fev$fev)
lines(loess, col = "blue", lty = 2)

# add a legend
legend('topleft',
       legend=c('Data','Linear Regression Line','Loess Smooth'),
       col = c('black','red','blue'), lty = c(NA,1,2),
       pch = c(16,NA,NA))
```

Compare and contrast the two trend lines. Do you think these trend lines make it easier to describe the trends in FEV with age?

*The loess line is very close to the linear regression line for small values of age. Once age gets to about 12, it looks like the loess line starts to flatten out a bit relative to the linear regression line. In either case, these trend lines do help confirm that there is a generally increasing trend/positive association between FEV and age, and confirm the pattern our eye might have been picking up on before we added these lines. Sometimes, the trend is not as obvious just from looking at the data points, so in those cases it is especially helpful to add a trend line.*


## 5. Linear regression with log transformed predictor

Now, we will use `R` to fit a regression model with log-transformed age as the predictor: $$E[\log(\text{FEV})|\log(\text{age})] = \beta_0 + \beta_1 \log(\text{age}).$$

`r colFmt("DISCLAIMER:","red")` we do not have a scientific motivation for log transforming age, but we're still going to look at this model, purely as an example of how to fit a model with a log transformed predictor. (It might actually be reasonable to log transform our outcome FEV (a biological measurement), but we will not look at that today.)

There are a few ways that we can ask `R` to fit this model for us. 

First, add the variable `logage` to your dataset and run linear regression with `logage` as your predictor rather than `age`.

```{r transform-1, eval = TRUE}
## add logage to dataset
fev$logage <- log(fev$age)

## run linear regression with log(age) as predictor
regress('mean', fev~logage, data=fev)
```

(*Again, you should not include raw `R` output like $\uparrow$ in a formal report, but we included it here so you could see what answers you should have gotten.*)

Remember that when we interpret the coefficients from a model with $\log(X)$ as our predictor, $\beta_1$ represents the difference in average $Y$ comparing two groups that differ in $X$ by a multiplicative factor of $e$. Since this is not a very intuitive interpretation, we prefer to interpret $\log(k)\times \beta_1$ rather than $\beta_1$. Let's look at $k=2$. Update the following code chunk with the estimate of $\beta_1$ that you got from `regress`, above. Then report your interpretation of $\beta_0$ and $\log(2)\beta_1$ below.

```{r interpret-1, eval = TRUE}
## estimate of beta_1 from regress
b1 <- 2.093
## now, interpret this value rather than beta_1:
log(2)*b1
## we can also update our confidence interval to be more interpretable:
b1_ci <- c(1.939,2.247) # lower and upper bounds of beta_1 CI from regress
log(2)*b1_ci 
```

*We estimate that the average FEV among 1 year olds is -2.07 liters per second (NOTE: this makes no scientific sense! you can't have a negative FEV value...). Furthermore, we estimate that the difference in average FEV comparing two groups that differ in age by a multiplicative factor of 2 is 1.45 liters per second. Based on a 95% confidence interval, this estimated difference would not be judged unusual if the true difference were between 1.34 and 1.56 liters per second.*

A second option is to specify the transformation within the `regress` command. This saves us one step by eliminating the need to add the variable `logage` to our dataset. Run the following code chunk (and add any code you need to help interpret your coefficients).

```{r transform-2, eval = TRUE}
## run linear regression with log(age) as predictor
regress('mean', fev~log(age), data=fev)

## don't forget to multiply beta_1 by log(2) so we can interpret!
log(2)*2.093 # interpret beta_1
log(2)*c(1.939,2.247) # interpret CI for beta_1
```

Do you get the same output using this approach as you did earlier?

*Yes, this is the same as above!*

As we discussed in class yesterday, a third option is to use log base 2 (i.e., $\log_2$) to transform our predictor rather than to use the natural log and have to interpret $\log_e(2)\beta_1$, as we did above. Let's try fitting this model with $\log_2(\text{age})$ now. 

```{r transform-3, eval = TRUE}
## run linear regression with log_2(age) as predictor
regress('mean', fev ~ log(age,base=2), data = fev)
```

Compare the results you got using this third approach to the output/interpretation from the earlier two models.

*We get the same estimate of $\beta_0$, and it has the same interpretation (the average FEV among 1 year olds). Our estimate of $\beta_1$ has changed (now 1.45 rather than 2.09), but our interpretation is the same (and we can interpret $\beta_1$ outright rather than having to interpret $\log(2)\beta_1$): We estimate that the difference in average FEV comparing two groups that differ in age by a multiplicative factor of 2 is 1.45 liters per second. Based on a 95% confidence interval, this estimated difference would not be judged unusual if the true difference were between 1.34 and 1.56 liters per second.*

List these three approaches in order of your preference (i.e., which do you like best? worst?), and explain your reasoning.

*To a certain extent, this is personal preference. But, our least favorite is the first approach (which first added `logage` to our fev dataset) because it involved that extra step of creating a new variable. Between the other two approaches, our preference might depend on what types of comparisons we're interested in. If we know from the start that we're interested in comparing groups that differ in age by a multiplicative factor of 2, then the $\log_2$ model might be preferable since it involves the fewest number of steps and doesn't require having to remember to interpret $\log(2)\beta_1$ rather than $\beta_1$. However, as we've seen above, all three approaches lead to exactly the same results and interpretation, so choose the approach that feels most comfortable/intuitive to you!*

Finally, let's create a plot that graphically supports our linear regression results.

```{r plot-transform, eval = TRUE}
## insert code for plot
## first, create a scatterplot of fev vs log(age)
plot(x = log(fev$age), y = fev$fev,
     xlim = c(1,3), ylim = c(0,7),
     xlab='Log of age (log-years)', ylab = 'FEV (liters/sec)',
     main='FEV vs log(age)',
     pch=16)
## then, use abline() to add your linear regression line
b0 <- -2.071
b1 <- 2.093
abline(a = b0, b = b1, col='red')
## you can also add a loess smooth using lowess() and lines()
loess <- lowess(x=log(fev$age), y = fev$fev)
lines(loess, col='blue', lty=2)
## add a legend
legend('topleft',
       legend=c('Data','Linear Regression Line','Loess Smooth'),
       col = c('black','red','blue'), lty = c(NA,1,2),
       pch = c(16,NA,NA))
```

*In this example, it looks like our best fitting line does not provide as great of a fit to our data. This is a possible indication of a non-linear relationship between FEV and log(age), so it probably wasn't a great idea to look at FEV vs log(age)---but we already guessed that, based on (lack of) scientific reasoning. So, as a final reminder: this is a setting where we would not want to log transform our predictor. But, now you know how to fit that type of model in `R` and how to interpret your coefficients if you do find yourself in a situation where there is a scientific motivation to log transform your predictor!* 



# Summary

As you're starting to see, `R` is a very powerful tool for summarizing data (both numerically and graphically) and fitting regression models. 

After this activity, you now know how to:

0. Add new variables to a dataset using `$`
1. Generate numerical summaries using the function `descrip`
2. Generate graphical summaries using the functions `boxplot` and `plot`
    a. Update axis limits using the arguments `xlim`,`ylim`
    b. Update axis labels using the arguments `xlab`,`ylab`
    c. Update figure titles using the argument `main`
    d. Change shapes and colors using the arguments `pch` and `col`
    e. Add points to a figure using the function `points()`
    f. Add lines to a figure using the functions `abline()` or `lines()`
    g. Add a legend using the function `legend()`
3. Run linear regression using `regress`
4. Run linear regression with a transformed variable using `regress`

Most of the analyses we'll conduct throughout the rest of the quarter will use these same tools, so you're now very far on your way to being able to use `R` for statistical analyses!


